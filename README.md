# **Behavioral Cloning** 

This project mainly focuses on mimicing humans' driving behaviors via neural network and simulating it into the Game.

---

**Behavioral Cloning Project**

The goals / steps of this project are the following:
* Use the simulator to collect data of humans' driving behaviors. It was generated by three different cameras  (left, mid, right) embedded in the font of the car.
* Construct a neural network in keras in order to solve the regression problem, which is by training the network to predict how much of the angle the car should shift.
* Train and validate the model with a training and validation set.
* Test that the model successfully drives around track one without leaving the road.


[//]: # (Image References)

[image1]: ./examples/placeholder.png "Model Visualization"
[image2]: ./examples/placeholder.png "Grayscaling"
[image3]: ./examples/placeholder_small.png "Recovery Image"
[image4]: ./examples/placeholder_small.png "Recovery Image"
[image5]: ./examples/placeholder_small.png "Recovery Image"
[image6]: ./examples/placeholder_small.png "Normal Image"
[image7]: ./examples/placeholder_small.png "Flipped Image"

## Rubric Points
### Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation.  

---
### Files Submitted & Code Quality

#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode

My project includes the following files:
* model.py containing the script to create and train the model.
* drive.py for driving the car in autonomous mode.
* model.hdf5 containing a trained convolution neural network.
* writeup_report.md or writeup_report.pdf summarizing the results.

#### 2. Submission includes functional code
Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing 
```sh
python drive.py model.h5
```

#### 3. Submission code is usable and readable

The model.py file contains the code for training and saving the best weights of my convolution neural network. The file contains comments to show how each function works. And I have all functions compacted in the model.py.

### Model Architecture and Training Strategy

#### 1. An appropriate model architecture has been employed

I was inspired by the paper [End to End Learning for Self-Driving Cars](https://arxiv.org/abs/1604.07316) from NVIDIA. And also I have modified the activation functions into 'RELU' instead of 'ELU'. 

My model has total nine layers. The first five layers are all convolutional layers and the rest of the four are fully-connected layers. Among the convolutional layers, the first three are convolved by 5x5 filters, and the other two are convolved by 3x3 filters. The number of filters are 24, 36, 48, 64, 64 respectively (model.py lines 99-103).

The other four fully-connected layers have their sizes 100, 50, 10, 1 respectively (model.py lines 105-108).

And the difference between my network and network in the paper is the activation functions. I changed activations function of all convolutional layers (model.py lines 99-103).

#### 2. Attempts to reduce overfitting in the model

My model only picks the best weights after training and validation.

My weights was put into the simulator to ensure there is no overfitting in the model.

#### 3. Model parameter tuning

My model uses 'Adam' optimizer and it has such properties:
```sh
m_0 <- 0 (Initialize initial 1st moment vector)
v_0 <- 0 (Initialize initial 2nd moment vector)
t <- 0 (Initialize timestep)
```
The update rule for variable with gradient g:
```sh
t <- t + 1
lr_t <- learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)

m_t <- beta1 * m_{t-1} + (1 - beta1) * g
v_t <- beta2 * v_{t-1} + (1 - beta2) * g * g
variable <- variable - lr_t * m_t / (sqrt(v_t) + epsilon)
```
Also, it has defult epsilon which is 1e-08 and its value of weight_decay is 0.0.

#### 4. Appropriate training data

Because there are total three cameras embedded in the front of the car, I used all of them to generate proper data for training. For example, the simulator creates a file named 'driving_log.csv' which contains all three images' names (center, left, right) captured by three different cameras and those images are contained in the folder named '/IMG'. Besides, the 'driving_log.csv' contains the steering_angle, speed, throttle, brake_flag data. In this project I only used steering_angle as training label since the speed is controlled by the throttle and brake and its value affects nothing much but the GPU processing speed.

### Model Architecture and Training Strategy

#### 1. Visualizing the data & modifying it


#### 2. Model Architecture

The final model architecture (model.py lines 18-24) consisted of a convolution neural network with the following layers and layer sizes ...

Here is a visualization of the architecture (note: visualizing the architecture is optional according to the project rubric)

![alt text][image1]

#### 3. Training Process & Results

To capture good driving behavior, I first recorded two laps on track one using center lane driving. Here is an example image of center lane driving:

![alt text][image2]

